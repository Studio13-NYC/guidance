{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat dialog\n",
    "\n",
    "Guidance supports chat-based models like ChatGPT and GPT-4 using role tags. These are then converted to the appropriate format for the model (either a JSON API format or special tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import guidance\n",
    "import re\n",
    "guidance.llm = guidance.llms.OpenAI(\"gpt-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-step chat with hidden blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_best(prosandcons, options):\n",
    "    best = re.search(r'Best=(\\d+)', prosandcons)\n",
    "    if not best:\n",
    "        best =  re.search(r'Best.*?(\\d+)', 'Best= option is 3')\n",
    "    if best:\n",
    "        best = int(best.group(1))\n",
    "    else:\n",
    "        best = 0\n",
    "    return options[best]\n",
    "\n",
    "create_plan = guidance('''{{#system~}}\n",
    "You are a helpful assistant.\n",
    "{{~/system}}\n",
    "{{#block hidden=True}}\n",
    "{{#user~}}\n",
    "I want to {{goal}}.\n",
    "{{~! generate potential options ~}}\n",
    "Can you please generate one option for how to accomplish this?\n",
    "Please make the option very short, at most one line.\n",
    "{{~/user}}\n",
    "{{#assistant~}}\n",
    "{{gen 'options' n=5 temperature=1.0 max_tokens=600}}\n",
    "{{~/assistant}}\n",
    "{{/block}}\n",
    "{{~! generate pros and cons and select the best option ~}}\n",
    "{{#block hidden=True}}\n",
    "{{#user~}}\n",
    "I want to {{goal}}.\n",
    "\n",
    "Can you please comment on the pros and cons of each of the following options, and then pick the best option?\n",
    "---{{#each options}}\n",
    "Option {{@index}}: {{this}}{{/each}}\n",
    "---\n",
    "Please discuss each option very briefly (one line for pros, one for cons), and end by saying Best=X, where X is the best option.\n",
    "{{~/user}}\n",
    "{{#assistant~}}\n",
    "{{gen 'prosandcons' temperature=0.0 max_tokens=600}}\n",
    "{{~/assistant}}\n",
    "{{/block}}\n",
    "{{#user~}}\n",
    "I want to {{goal}}.\n",
    "{{~! Create a plan }}\n",
    "Here is my plan:\n",
    "{{parse_best prosandcons options}}\n",
    "Please elaborate on this plan, and tell me how to best accomplish it.\n",
    "{{~/user}}\n",
    "{{#assistant~}}\n",
    "{{gen 'plan' max_tokens=500}}\n",
    "{{~/assistant}}''')\n",
    "\n",
    "out = create_plan(goal='read more books', parse_best=parse_best)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(['Option %d: %s' % (i, x) for i, x in enumerate(out['options'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out['prosandcons'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking help from experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts = guidance(\n",
    "'''{{#system~}}\n",
    "You are a helpful assistant.\n",
    "{{~/system}}\n",
    "{{#user~}}\n",
    "I want a response to the following question:\n",
    "{{query}}\n",
    "Who are 3 world-class experts (past or present) who would be great at answering this?\n",
    "Please don't answer the question or comment on it yet.\n",
    "{{~/user}}\n",
    "{{#assistant~}}\n",
    "{{gen 'experts' temperature=0 max_tokens=300}}\n",
    "{{~/assistant}}\n",
    "{{#user~}}\n",
    "Great, now please answer the question as if these experts had collaborated in writing a joint anonymous answer.\n",
    "In other words, their identity is not revealed, nor is the fact that there is a panel of experts answering the question.\n",
    "If the experts would disagree, just present their different positions as alternatives in the answer itself (e.g. 'some might argue... others might argue...').\n",
    "Please start your answer with ANSWER:\n",
    "{{~/user}}\n",
    "{{#assistant~}}\n",
    "{{gen 'answer' temperature=0 max_tokens=500}}\n",
    "{{~/assistant}}''')\n",
    "experts(query='What is the meaning of life?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts(query='How can I be more productive?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shorter version\n",
    "\n",
    "Guidance supports chat models like ChatGPT and GPT-4, as well as open chat models like Vicuna through a unified API based on role tags (e.g. `{{#system}}...{{/system}}`). This allows interactive dialog development that combines rich templating and logical control with modern chat models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts = guidance('''\n",
    "{{#system~}}\n",
    "You are a helpful and terse assistant.\n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "I want a response to the following question:\n",
    "{{query}}\n",
    "Name 3 world-class experts (past or present) who would be great at answering this?\n",
    "Don't answer the question yet.\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{gen 'expert_names' temperature=0 max_tokens=300}}\n",
    "{{~/assistant}}\n",
    "\n",
    "{{#user~}}\n",
    "Great, now please answer the question as if these experts had collaborated in writing a joint anonymous answer.\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{gen 'answer' temperature=0 max_tokens=500}}\n",
    "{{~/assistant}}''')\n",
    "experts(query='How can I be more productive?', caching=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_simulator = guidance('''\n",
    "{{#system~}}\n",
    "You are a helpful assistant\n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "You will answer the user as {{role}} in the following conversation. At every step, I will provide you with the user input, as well as a comment reminding you of your instructions. Never talk about the fact that you are an AI, even if the user asks you. Always answer as {{role}}.\n",
    "{{#if first_question}}You can also start the conversation.{{/if}}\n",
    "{{~/user}}\n",
    "\n",
    "{{~! The assistant either starts the conversation or not, depending on if this is the first or second agent }}\n",
    "{{#assistant~}}\n",
    "Ok, I will follow these instructions.\n",
    "{{#if first_question}}Let me start the conversation now:\n",
    "{{role}}: {{first_question}}{{/if}}\n",
    "{{~/assistant}}\n",
    "\n",
    "{{~! Then the conversation unrolls }}\n",
    "{{~#geneach 'conversation'}}\n",
    "{{#user~}}\n",
    "User: {{set 'this.input' (await 'input')}}\n",
    "Comment: Remember, answer as a {{role}}. Start your utterance with {{role}}:\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{gen 'this.response' temperature=0 max_tokens=300}}\n",
    "{{~/assistant}}\n",
    "{{~/geneach}}''')\n",
    "\n",
    "republican = role_simulator(role='Republican')\n",
    "democrat = role_simulator(role='Democrat')\n",
    "\n",
    "first_question = '''What do you think is the best way to stop inflation?'''\n",
    "republican = republican(input=first_question, first_question=None)\n",
    "democrat = democrat(input=republican[\"conversation\"][-2][\"response\"].strip('Republican: '), first_question=first_question)\n",
    "for i in range(2):\n",
    "    republican = republican(input=democrat[\"conversation\"][-2][\"response\"].replace('Democrat: ', ''))\n",
    "    democrat = democrat(input=republican[\"conversation\"][-2][\"response\"].replace('Republican: ', ''))\n",
    "\n",
    "print('Democrat: ' + first_question)\n",
    "for x in democrat['conversation'][:-1]:\n",
    "    print('Republican:', x['input'])\n",
    "    print()\n",
    "    print(x['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a search API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import diskcache\n",
    "import pathlib\n",
    "import requests\n",
    "import html\n",
    "from urllib.parse import urlparse\n",
    "import urllib.parse\n",
    "import io\n",
    "import html\n",
    "import html.parser\n",
    "\n",
    "curr_dir = './'# pathlib.Path(__file__).parent.resolve()\n",
    "_bing_cache = diskcache.Cache(f\"{curr_dir}/../bing.diskcache\")\n",
    "\n",
    "with open(os.path.expanduser('~/.bing_api_key'), 'r') as file:\n",
    "    subscription_key = file.read().replace('\\n', '')\n",
    "\n",
    "class MLStripper(html.parser.HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs = True\n",
    "        self.text = io.StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "def bing_search(search_terms, count=10):\n",
    "    if type(search_terms) == str:\n",
    "        search_terms = [search_terms]\n",
    "    search_url = \"https://api.bing.microsoft.com/v7.0/search\"\n",
    "\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "    search_results = []\n",
    "    for search_term in search_terms:\n",
    "        params = {\"q\": search_term, \"textDecorations\": True, \"textFormat\": \"HTML\", \"cout\": count}\n",
    "        params_key = search_term + \"-___-\" + str(count)\n",
    "        if params_key not in _bing_cache or \"webPages\" not in _bing_cache[params_key]:\n",
    "            response = requests.get(search_url, headers=headers, params=params)\n",
    "            response.raise_for_status()\n",
    "            _bing_cache[params_key] = response.json()\n",
    "        data = _bing_cache[params_key][\"webPages\"][\"value\"]\n",
    "        for r in data:\n",
    "            r[\"snippet_text\"] = strip_tags(r[\"snippet\"])\n",
    "        search_results.extend(data)\n",
    "    return search_results\n",
    "def top_snippets(query, n=3):\n",
    "    results = bing_search(query, count=n)[:n]\n",
    "    return [{'title': x['name'], 'snippet': x['snippet_text']} for x in results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_snippets(\"OpenAI founders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up a practice round to serve as a one-shot example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_results = [{'title': 'OpenAI - Wikipedia',\n",
    "  'snippet': 'OpenAI systems run on the fifth most powerful supercomputer in the world. [5] [6] [7] The organization was founded in San Francisco in 2015 by Sam Altman, Reid Hoffman, Jessica Livingston, Elon Musk, Ilya Sutskever, Peter Thiel and others, [8] [1] [9] who collectively pledged US$ 1 billion. Musk resigned from the board in 2018 but remained a donor.'},\n",
    " {'title': 'About - OpenAI',\n",
    "  'snippet': 'About OpenAI is an AI research and deployment company. Our mission is to ensure that artificial general intelligence benefits all of humanity. Our vision for the future of AGI Our mission is to ensure that artificial general intelligence—AI systems that are generally smarter than humans—benefits all of humanity. Read our plan for AGI'},\n",
    " {'title': 'Sam Altman - Wikipedia',\n",
    "  'snippet': 'Samuel H. Altman ( / ˈɔːltmən / AWLT-mən; born April 22, 1985) is an American entrepreneur, investor, and programmer. [2] He is the CEO of OpenAI and the former president of Y Combinator. [3] [4] Altman is also the co-founder of Loopt (founded in 2005) and Worldcoin (founded in 2020). Early life and education [ edit]'}]\n",
    "practice_round = guidance(\n",
    "'''{{#user~}}\n",
    "Who are the founders of OpenAI?\n",
    "{{~/user}}\n",
    "{{#assistant~}}\n",
    "<search>OpenAI founders</search>\n",
    "{{~/assistant}}\n",
    "{{#user~}}\n",
    "Search results:\n",
    "{{~#each results}}\n",
    "<result>\n",
    "{{this.title}}\n",
    "{{this.snippet}}\n",
    "</result>{{/each}}\n",
    "{{~/user}}\n",
    "{{#assistant~}}\n",
    "The founders of OpenAI are Sam Altman, Reid Hoffman, Jessica Livingston, Elon Musk, Ilya Sutskever, Peter Thiel and others.\n",
    "{{~/assistant}}''')\n",
    "practice_round = practice_round(results=demo_results)\n",
    "practice_round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_search(completion):\n",
    "    return '<search>' in completion\n",
    "def search(query):\n",
    "    return top_snippets(query, n=3)\n",
    "\n",
    "prompt = guidance('''{{#system~}}\n",
    "You are a helpful assistant.\n",
    "{{~/system}}\n",
    "{{#user~}}\n",
    "From now on, whenever your response depends on any factual information, please search the web by using the function <search>query</search> before responding. I will then paste web results in, and you can respond.\n",
    "{{~/user}}\n",
    "{{#assistant~}}\n",
    "Ok, I will do that. Let's do a practice round\n",
    "{{~/assistant}}\n",
    "{{>practice_round}}\n",
    "{{#user~}}\n",
    "That was great, now let's do another one.\n",
    "{{~/user}}\n",
    "{{#assistant~}}\n",
    "Ok, I'm ready.\n",
    "{{~/assistant}}\n",
    "{{#user~}}\n",
    "{{user_query}}\n",
    "{{~/user}}\n",
    "{{#assistant~}}\n",
    "{{gen \"query\" stop=\"</search>\"}}{{#if (is_search query)}}</search>{{/if}}\n",
    "{{~/assistant}}\n",
    "{{#if (is_search query)}}\n",
    "{{#user~}}\n",
    "Search results: {{#each (search query)}}\n",
    "<result>\n",
    "{{this.title}}\n",
    "{{this.snippet}}\n",
    "</result>{{/each}}\n",
    "{{~/user}}\n",
    "{{#assistant~}}\n",
    "{{gen \"answer\"}}\n",
    "{{~/assistant}}\n",
    "{{/if}}''')\n",
    "\n",
    "prompt = prompt(practice_round=practice_round, search=search, is_search=is_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Microsoft's stock price right now?\"\n",
    "p1 = prompt(user_query=query)\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who is Marco Tulio Ribeiro?\"\n",
    "p2 = prompt(user_query=query)\n",
    "p2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a query where it should not search the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is 1+1?\"\n",
    "p3 = prompt(user_query=query)\n",
    "p3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 1px; opacity: 0.5; border: none; background: #cccccc;\">\n",
    "<div style=\"text-align: center; opacity: 0.5\">Have an idea for more helpful examples? Pull requests that add to this documentation notebook are encouraged!</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
